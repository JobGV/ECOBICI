{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07924cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14068a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Indicador del tipo de red por horario  \n",
    "Tipo = \"_Hor.csv\"\n",
    "TipoS = \"_Hor4.csv\"\n",
    "Condicion = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "mexico_city_map = Basemap(llcrnrlon=-99.4, llcrnrlat=19.1, urcrnrlon=-98.8, urcrnrlat=19.7, resolution='l', epsg=4326)\n",
    "# Cargamos las coordenadas de las estaciones \n",
    "ecobici_coordenadas = pd.read_csv(\"https://raw.githubusercontent.com/JobGV/ECOBICI/main/Dictionary/Cordenadas_Ecobici.csv\")\n",
    "ecobici_coordenadas = ecobici_coordenadas.rename(columns={'id':'source','Latitud':'longitud','Longitud':'latitud'})\n",
    "pos =ecobici_coordenadas[['source','latitud','longitud']]\n",
    "# Asignamos las coordenadas \n",
    "mx, my =mexico_city_map(ecobici_coordenadas[['longitud']],ecobici_coordenadas[['latitud']])\n",
    "ecobici_coordenadas[['longitud']]=mx\n",
    "ecobici_coordenadas[['latitud']] = my\n",
    "pos['location']=pos[['latitud','longitud']].apply(tuple,axis=1)\n",
    "pos=pos[['source','location']]\n",
    "pos_dic = dict(zip(pos['source'], pos['location']))\n",
    "\n",
    "Year=[2019,2020,2021]\n",
    "\n",
    "for i in range(3):\n",
    "    rutaR =\"https://raw.githubusercontent.com/JobGV/ECOBICI/main/Clean/\"+str(Year[i])+Tipo\n",
    "    ecobici = pd.read_csv(rutaR)\n",
    "    \n",
    "    ecobici = ecobici[ecobici['Horario']==Condicion]\n",
    "    \n",
    "    ecobici = ecobici.rename(columns={'Ciclo_Estacion_Retiro':'source','Ciclo_Estacion_Arribo':'target'})\n",
    "    edges = ecobici[['source', 'target','Viajes']].reset_index(drop=True) \n",
    "    edges=edges.rename(columns={'Viajes':'weight'})\n",
    "    \n",
    "    # Ajustamos la red \n",
    "    G=nx.from_pandas_edgelist(edges,source='source',target='target',edge_attr='weight',create_using=nx.DiGraph())\n",
    "    nx.set_node_attributes(G, pos_dic, 'coord')\n",
    "    \n",
    "    # Seleccionamos el top n\n",
    "    n=200\n",
    "    # Calulamos in-degree y out-degree\n",
    "    in_deg_cent = nx.in_degree_centrality(G)\n",
    "    out_deg_cent = nx.out_degree_centrality(G)\n",
    "    in_deg_central = pd.DataFrame(in_deg_cent.items(), columns=['id', 'in_deg_cent'])\n",
    "    out_deg_central = pd.DataFrame(out_deg_cent.items(), columns=['id', 'out_deg_cent'])\n",
    "    Top_in = in_deg_central.nlargest(n,'in_deg_cent')\n",
    "    Top_out = out_deg_central.nlargest(n,'out_deg_cent')\n",
    "\n",
    "    lst1 = Top_in.id.values.tolist() \n",
    "    lst2 = Top_in.in_deg_cent.values.tolist()\n",
    "    lst3 = ['in_deg_cent']*n\n",
    "    Centralidades = pd.DataFrame(list(zip(lst1,lst2,lst3)),columns=['id','value','mesure'])\n",
    "\n",
    "    lst1 = Top_out.id.values.tolist() \n",
    "    lst2 = Top_out.out_deg_cent.values.tolist()\n",
    "    lst3 = ['out_deg_cent']*n\n",
    "    aux = pd.DataFrame(list(zip(lst1,lst2,lst3)),columns=['id','value','mesure'])\n",
    "\n",
    "    Centralidades = pd.concat([Centralidades,aux])\n",
    "    \n",
    "    # Calculamos la centralidad de cercania \n",
    "    close_cent=nx.closeness_centrality(G)\n",
    "    close_central=pd.DataFrame(close_cent.items(), columns=['id', 'close_cent'])\n",
    "    Top_close=close_central.nlargest(n,'close_cent')\n",
    "\n",
    "    lst1 = Top_close.id.values.tolist() \n",
    "    lst2 = Top_close.close_cent.values.tolist()\n",
    "    lst3 = ['close_cent']*n\n",
    "    aux = pd.DataFrame(list(zip(lst1,lst2,lst3)),columns=['id','value','mesure'])\n",
    "\n",
    "    Centralidades = pd.concat([Centralidades,aux])\n",
    "\n",
    "    # Calculamos la centralidad betwenness\n",
    "    between_cent=nx.betweenness_centrality(G)\n",
    "    between_central=pd.DataFrame(between_cent.items(), columns=['id', 'between_cent'])\n",
    "    Top_between=between_central.nlargest(n,'between_cent')\n",
    "\n",
    "    lst1 = Top_between.id.values.tolist() \n",
    "    lst2 = Top_between.between_cent.values.tolist()\n",
    "    lst3 = ['between_cent']*n\n",
    "    aux = pd.DataFrame(list(zip(lst1,lst2,lst3)),columns=['id','value','mesure'])\n",
    "\n",
    "    Centralidades = pd.concat([Centralidades,aux])\n",
    "    #Calculamos el clustering promedio y el grado de asortatividad\n",
    "    lst1 = [0]*3\n",
    "    lst2 = [nx.average_clustering(G),nx.degree_assortativity_coefficient(G),nx.degree_pearson_correlation_coefficient(G)]\n",
    "    lst3 = ['average_clustering','degree_assortativity','degree_pearson_corr']\n",
    "\n",
    "    aux = pd.DataFrame(list(zip(lst1,lst2,lst3)),columns=['id','value','mesure'])\n",
    "    \n",
    "    # Creamos una base con todos todas las medidas de centralidad\n",
    "    Centralidades = pd.concat([Centralidades,aux])\n",
    "    Centralidades['Year']=Year[i]\n",
    "    #rutaS=\"C:\\\\Users\\\\benga\\\\OneDrive - El Colegio de México A.C\\\\Proyecto\\\\Redes\\\\Resultados\\\\Centralidades_\"+str(Year[i])+TipoS\n",
    "    #Centralidades.to_csv(rutaS,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934eb55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la base consolidada por género \n",
    "Year=[2019,2020,2021]\n",
    "rutaS=\"https://raw.githubusercontent.com/JobGV/ECOBICI/main/Medidas_Centralidad/Centralidades_\"+str(Year[2])+TipoS\n",
    "base = pd.read_csv(rutaS)\n",
    "\n",
    "for i in range(2):\n",
    "    rutaS=\"https://raw.githubusercontent.com/JobGV/ECOBICI/main/Medidas_Centralidad/Centralidades_\"+str(Year[i])+TipoS\n",
    "    aux = pd.read_csv(rutaS)\n",
    "    base= pd.concat([base,aux])\n",
    "\n",
    "Etiquetas = pd.read_csv(\"https://raw.githubusercontent.com/JobGV/ECOBICI/main/Dictionary/Estaciones.csv\")\n",
    "base = base.merge(Etiquetas,how='left',on='id')\n",
    "base['nombre'] = base['id'].astype(str)+\". \"+base['Estación']+\" (\"+round(base['value'],4).astype(str)+\")\"\n",
    "#ruta=\"C:\\\\Users\\\\benga\\\\OneDrive - El Colegio de México A.C\\\\Proyecto\\\\Redes\\\\Resultados\\\\Centralidades_Consolidado\"+TipoS\n",
    "#base.to_csv(ruta,index=False)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
